from tensorflow.keras.utils import plot_model
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import tensorflow as tf
import numpy as np
import pandas as pd
import tensorflow.keras.datasets.fashion_mnist as fmnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D,Dropout,MaxPooling2D,Flatten,Dense

dataset=fmnist.load_data()   
(X_train,Y_train),(X_test,Y_test)=dataset
X_train=X_train.reshape(-1,28,28,1)
X_test=X_test.reshape(-1,28,28,1)

X_train = X_train/255.0
X_test = X_test/255.0

Y_train = np.eye(10)[Y_train]
Y_test = np.eye(10)[Y_test]

def lr_schedule(epoch):
    lr = 1e-3
    if epoch > 150:
        lr *= 0.5e-3
    elif epoch > 80:
        lr *= 1e-3
    elif epoch > 40:
        lr *= 1e-2
    elif epoch > 20:
        lr *= 1e-1
    print('Learning rate: ', lr)
    return lr
	
model=Sequential()
model.add(Conv2D(filters=5,kernel_size=(3,3),strides=(1,1),input_shape=X_train.shape[1:],padding='same',
                 data_format='channels_last',activation='relu',kernel_initializer='uniform'))  #[None,28,28,5]
model.add(Dropout(0.2))
model.add(MaxPooling2D((2,2)))  #池化核大小[None,14,14,5]
model.add(tf.keras.layers.BatchNormalization()) 

model.add(Conv2D(16,(3,3),strides=(1,1),data_format='channels_last',padding='same',activation='relu',kernel_initializer='uniform'))#[None,12,12,16]
model.add(Dropout(0.2))
model.add(MaxPooling2D(2,2))  #output_shape=[None,6,6,16]
model.add(tf.keras.layers.BatchNormalization()) 

model.add(Conv2D(32, (3, 3), strides=(1, 1), data_format='channels_last', padding='same', activation='relu',
                 kernel_initializer='uniform'))   #[None,4,4,32]
model.add(Dropout(0.2))
model.add(tf.keras.layers.BatchNormalization()) 
# model.add(MaxPooling2D(2, 2))
model.add(Conv2D(100,(3,3),strides=(1,1),data_format='channels_last',activation='relu',kernel_initializer='uniform'))  #[None,2,2,100]
model.add(tf.keras.layers.BatchNormalization()) 
model.add(Flatten(data_format='channels_last'))  #[None,400]
model.add(Dense(168,activation='relu'))   #[None,168]
model.add(tf.keras.layers.BatchNormalization()) 
model.add(Dense(84,activation='relu'))    #[None,84]
model.add(tf.keras.layers.BatchNormalization()) 
model.add(Dense(10,activation='softmax'))  #[None,10]
#打印参数
model.summary()
#编译模型
model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr_schedule(0)),loss='categorical_crossentropy',metrics=['accuracy'])

lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)

if __name__ == '__main__':
	model.fit(x=X_train,y=Y_train,batch_size=128,epochs=1000,validation_data=(X_test,Y_test),callbacks=[lr_scheduler])
	#模型评估
	loss,acc=model.evaluate(x=X_test,y=Y_test)
	print("loss:{}===acc:{}".format(loss,acc))
